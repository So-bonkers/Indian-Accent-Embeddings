# -*- coding: utf-8 -*-
"""get glove.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aIXgXemZrdKsHy7B_wA5P9IjTHd0VxK6
"""

from google.colab import drive
drive.mount('/content/drive')

import pickle
file = open("/content/drive/My Drive/Colab Notebooks/train_data_first_50.pkl","rb")

!pip install glove_python

import numpy as np
import librosa
import os
from tqdm import tqdm
import pickle
from gensim.models import word2vec


with open("/content/drive/My Drive/Colab Notebooks/sentences_list.pkl","rb") as file:
  sentences_list = pickle.load(file)

print(sentences_list)
from glove import Corpus, Glove

#Creating a corpus object
corpus = Corpus() 

#Training the corpus to generate the co occurence matrix which is used in GloVe
corpus.fit(sentences_list, window=10)

glove = Glove(no_components=100, learning_rate=0.05) 
glove.fit(corpus.matrix, epochs=60, no_threads=4, verbose=True)
glove.add_dictionary(corpus.dictionary)
glove.save('/content/drive/My Drive/Colab Notebooks/glove.model')

# model = word2vec.Word2Vec(sentences_list, sg=1, size=100, window=3, min_count=1)  # sg=1 表示skip-gram模型
# # print(model['keep'])
# # print(model.most_similar(['love']))
# model.wv.save_word2vec_format('glove_first_50.txt', binary=False)

glove.word_vectors[glove.dictionary['the']]

from gensim.test.utils import datapath, get_tmpfile
from gensim.models import KeyedVectors
from gensim.scripts.glove2word2vec import glove2word2vec

glove_file = datapath('/content/drive/My Drive/Colab Notebooks/glove.model')
tmp_file = get_tmpfile("/content/drive/My Drive/Colab Notebooks/glove_word2vec.txt")
with open("/content/drive/My Drive/Colab Notebooks/glove_word2vec.txt", "w") as f:
    for word in glove.dictionary:
        f.write(word)
        f.write(" ")
        for i in range(0, 100):
            f.write(str(glove.word_vectors[glove.dictionary[word]][i]))
            f.write(" ")
        f.write("\n")