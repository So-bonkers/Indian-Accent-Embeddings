{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec: Pytorch Implementation\n",
    "\n",
    "## Preface: On Embeddings\n",
    "\n",
    "The utility of embedding methods is linked to the original challenges motivating text-as-data methods. Byrepresenting natural language numerically, embedding methods offer the possibility to leverage a broad range of quantitative tools on hitherto unusable sources of data. \n",
    "\n",
    "At a high level, word embeddings represent the individual words (vocabulary) of a collection of texts (corpus) as vectors in a k-dimensional space. These vectors encode information about the relationbship between words and their context, and are used for downstream language modelling tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Loading the data\n",
    "\n",
    "As with any NLP task (in general), there are two main steps to be followed:\n",
    " * Preparing the data (the loading)\n",
    " * Processing the data (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/shubhankar/.local/lib/python3.8/site-packages (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in /home/shubhankar/.local/lib/python3.8/site-packages (from torch) (4.0.1)\n",
      "Requirement already satisfied: nltk in /home/shubhankar/.local/lib/python3.8/site-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/shubhankar/.local/lib/python3.8/site-packages (from nltk) (2022.4.24)\n",
      "Requirement already satisfied: joblib in /home/shubhankar/.local/lib/python3.8/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in /home/shubhankar/.local/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /home/shubhankar/.local/lib/python3.8/site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: datasets in /home/shubhankar/.local/lib/python3.8/site-packages (2.2.2)\n",
      "Requirement already satisfied: aiohttp in /home/shubhankar/.local/lib/python3.8/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: xxhash in /home/shubhankar/.local/lib/python3.8/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/shubhankar/.local/lib/python3.8/site-packages (from datasets) (1.22.2)\n",
      "Requirement already satisfied: pandas in /home/shubhankar/.local/lib/python3.8/site-packages (from datasets) (1.4.0)\n",
      "Requirement already satisfied: multiprocess in /home/shubhankar/.local/lib/python3.8/site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/shubhankar/.local/lib/python3.8/site-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/shubhankar/.local/lib/python3.8/site-packages (from datasets) (8.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /home/shubhankar/.local/lib/python3.8/site-packages (from datasets) (0.6.0)\n",
      "Requirement already satisfied: dill<0.3.5 in /home/shubhankar/.local/lib/python3.8/site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: packaging in /home/shubhankar/.local/lib/python3.8/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/shubhankar/.local/lib/python3.8/site-packages (from datasets) (2022.5.0)\n",
      "Requirement already satisfied: responses<0.19 in /home/shubhankar/.local/lib/python3.8/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/lib/python3/dist-packages (from datasets) (2.22.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/shubhankar/.local/lib/python3.8/site-packages (from aiohttp->datasets) (2.0.12)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/shubhankar/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/shubhankar/.local/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/shubhankar/.local/lib/python3.8/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/shubhankar/.local/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/shubhankar/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/shubhankar/.local/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/shubhankar/.local/lib/python3.8/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/shubhankar/.local/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.3.1)\n",
      "Requirement already satisfied: filelock in /home/shubhankar/.local/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/shubhankar/.local/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/shubhankar/.local/lib/python3.8/site-packages (from packaging->datasets) (3.0.7)\n",
      "Requirement already satisfied: urllib3>=1.25.10 in /home/shubhankar/.local/lib/python3.8/site-packages (from responses<0.19->datasets) (1.26.9)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp->datasets) (2.8)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "Using custom data configuration default\n",
      "Reusing dataset tweets_hate_speech_detection (/home/shubhankar/.cache/huggingface/datasets/tweets_hate_speech_detection/default/0.0.0/c6b6f41e91ac9113e1c032c5ecf7a49b4e1e9dc8699ded3c2d8425c9217568b2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011820e6c2c443e983fd624bf1956acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install nltk\n",
    "!pip install datasets\n",
    "import torch\n",
    "import datasets\n",
    "\n",
    "dataset = datasets.load_dataset('tweets_hate_speech_detection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a function to split up the raw tweets into lists of tokens. For this, the preprocessing itself is kept very simple, and apply:\n",
    "1. Lowercase all\n",
    "2. Remove all symbols other than a-z@#\n",
    "3. Split on spaces.\n",
    "4. Remove stopwords/empty tokens.\n",
    "5. Apply snowball stemmer to remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/shubhankar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Loading cached processed dataset at /home/shubhankar/.cache/huggingface/datasets/tweets_hate_speech_detection/default/0.0.0/c6b6f41e91ac9113e1c032c5ecf7a49b4e1e9dc8699ded3c2d8425c9217568b2/cache-1881b7d4fd39d6eb.arrow\n"
     ]
    }
   ],
   "source": [
    "# We'll remove alphanumeric but keep @,#\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "ss = SnowballStemmer('english')\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "def split_tokens(row):\n",
    "    row['all_tokens'] = [ss.stem(i) for i in \n",
    "                      re.split(r\" +\", \n",
    "                      re.sub(r\"[^a-z@# ]\", \"\",\n",
    "                            row['tweet'].lower()))\n",
    "                      if (i not in sw) and len(i)]\n",
    "    return row\n",
    "\n",
    "#Determine vocabulary so we can create mapping\n",
    "dataset = dataset.map(split_tokens) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these we can construct some useful variables for the future. But first let's remove tokens that occur fewer than 10 times to reduce the size of our vocabulary.\n",
    "* ```counts```: Total word counts\n",
    "* ```vocab```: Unique tokens in corpus\n",
    "* ```n_v```: Size of vocabulary\n",
    "* ```id2tok/tok2id```: Move back and forth between tokens and numeric ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/shubhankar/.cache/huggingface/datasets/tweets_hate_speech_detection/default/0.0.0/c6b6f41e91ac9113e1c032c5ecf7a49b4e1e9dc8699ded3c2d8425c9217568b2/cache-fccb5fdd1de69816.arrow\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter([i for s in dataset['train']['all_tokens'] for i in s])\n",
    "counts = {k:v for k,v in counts.items() if v>10} #filtering\n",
    "vocab = list(counts.keys())\n",
    "n_v = len(vocab) \n",
    "id2tok = dict(enumerate(vocab))\n",
    "tok2id = {token: id for id, token in id2tok.items()}\n",
    "\n",
    "# Now correct tokens \n",
    "def remove_rare_tokens(row):\n",
    "    row['tokens'] = [t for t in row['all_tokens'] if t in vocab]\n",
    "    return row\n",
    "\n",
    "dataset = dataset.map(remove_rare_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now finally we need to prepare the \"sliding window\" used in the word2vec algorithm. The target sentence is converted into pairs of ```target```, ```context``` where context is a list of the tokens within the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/shubhankar/.cache/huggingface/datasets/tweets_hate_speech_detection/default/0.0.0/c6b6f41e91ac9113e1c032c5ecf7a49b4e1e9dc8699ded3c2d8425c9217568b2/cache-9193f44e52fe397b.arrow\n"
     ]
    }
   ],
   "source": [
    "def windowizer(row, wsize=3):\n",
    "    \"\"\"\n",
    "    Windowizer function for Word2Vec. Converts sentence to sliding-window\n",
    "    pairs.\n",
    "    \"\"\"\n",
    "    doc = row['tokens']\n",
    "    wsize = 3\n",
    "    out = []\n",
    "    for i, wd in enumerate(doc):\n",
    "        target = tok2id[wd]\n",
    "        window = [i+j for j in\n",
    "                  range(-wsize, wsize+1, 1)\n",
    "                  if (i+j>=0) &\n",
    "                     (i+j<len(doc)) &\n",
    "                     (j!=0)]\n",
    "\n",
    "        out+=[(target, tok2id[doc[w]]) for w in window]\n",
    "    row['moving_window'] = out\n",
    "    return row\n",
    "\n",
    "dataset = dataset.map(windowizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build this into a PyTorch Dataset class so that we can pass it to a DataLoader class.\n",
    "\n",
    "The main advantages of using a DataLoader is the ability to efficiently manage VRAM usage and transfer between disk/RAM/VRAM. It also allows for multiprocessing on the loading/preprocessing side, which can provide speed-ups.\n",
    "\n",
    "The ```Dataset``` class requires the following 3 methods:\n",
    "\n",
    "* ```__init__```: This gets executed when the class in instantiated. Typically, here is where you define attributes, such as an underlying data object or a preprocessing step that you don't want to execute on-the-fly.\n",
    "* ```__len__```: This should return the length of the dataset. I assume it's important for knowing how much memory to allocate.\n",
    "* ```__getitem__```: Given an index, return the element of the dataset corresponding to the given index. \n",
    "\n",
    "What's happening here is:\n",
    "* We are building a single tensor to hold all (word, context-word) pairs, which we'll randomly sample from.\n",
    "* Returning the (word, context-word) pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Word2VecDataset(Dataset):\n",
    "    # Takes a dataset as input to be used for a Word2Vec dataloader\n",
    "    def __init__(self, dataset, vocab_size, wssize=3):\n",
    "        self.dataset = dataset\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = [i for s in dataset['moving_window'] for i in s]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we wrap the dataset with a DataLoader. Note that at this point I'm defining two \"global\" variables (in all caps): ```BATCH_SIZE``` and ```N_LOADER_PROCS```.\n",
    "\n",
    "```BATCH_SIZE``` is the number of observations returned with each call. Much of the speed-ups from GPU processing come from massive batched matrix computations. When choosing batch size, remember that it's generally at trade-off between VRAM usage and speed, except for when the the dataloader itself is the bottle. To speed up the dataloader, we can pass an argument to ```num_workers``` to enable parallelisation on the data preparation and loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2**14\n",
    "N_LOADER_PROCS = 10 \n",
    "\n",
    "dataloader = {}\n",
    "for key in dataset.keys():\n",
    "    dataloader = {key: DataLoader(Word2VecDataset(\n",
    "                                    dataset[key], vocab_size=n_v),\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    shuffle=True,\n",
    "                                    num_workers=N_LOADER_PROCS)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Building the Network\n",
    "\n",
    "Now that we've defined our loader, we can define our neural network. The way we build NNs in PyTorch may seem strange at first, but it quickly becomes natural. We use the same Python class structure to instantiate the \"building blocks\" in the ```__init__```, and then define the \"forward pass\" (i.e. the path from the input to the output) in the ```forward``` method. \n",
    "\n",
    "```Word2Vec``` architecture as defined by Mikolov:\n",
    "* 3 layers : input, hidden and output layer\n",
    "* Input and output are the size of the vocabulary. Hidden is smaller than either.\n",
    "* Fully connected with linear activations.\n",
    "\n",
    "There are 2 variants of this architecture:\n",
    "* ```CBOW``` (continuous bag-of-words): context word is input, center word is output.\n",
    "* ```skip-gram```: center word is input, context word is output.\n",
    "\n",
    "## Aside: Manually implementing one-hot encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]], requires_grad=True)\n",
      "tensor([3.], grad_fn=<SqueezeBackward3>)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "size=10\n",
    "input=3\n",
    "\n",
    "def one_hot_encode(input, size):\n",
    "    vec = torch.zeros(size).float()\n",
    "    vec[input] = 1.0\n",
    "    return vec\n",
    "\n",
    "ohe = one_hot_encode(input, size)\n",
    "linear_layer = nn.Linear(size, 1, bias=False)\n",
    "\n",
    "#Set edge weights from 0 to 9 for easy reference\n",
    "with torch.no_grad():\n",
    "    linear_layer.weight = nn.Parameter(\n",
    "        torch.arange(10, dtype=torch.float).reshape(linear_layer.weight.shape))\n",
    "\n",
    "print(linear_layer.weight)\n",
    "print(linear_layer(ohe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wut?\n",
    "\n",
    "1. Firstly, we created a tensor of zeros equal in size to the vocabulary, and then assign ```1``` to the value corresponding to our feature.\n",
    "2. We instantiate a linear layer with no bias, which is essentially a 10x1 tensor of edge weights.\n",
    "3. I overwrite the randomly initialized weights with the values 0-9. We wrap this in ```torch.no_grad``` to disable gradient tracking; in short, operations on PyTorch tensors with gradient descent tracking enabled are stored in order to differentiate the loss w.r.t. every parameter in the model. Because here I am manually setting the parameters, I don’t actually want this action to be stored and considered when making a future backprop calculation.\n",
    "4. When we pass our OH encoded vector, we retrieve the weight corresponding to the input id.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [9.]], requires_grad=True)\n",
      "tensor([3.], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = nn.Embedding(size, 1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    embedding_layer.weight = nn.Parameter(\n",
    "        torch.arange(10, dtype=torch.float\n",
    "                     ).reshape(embedding_layer.weight.shape))\n",
    "\n",
    "print(embedding_layer.weight)\n",
    "print(embedding_layer(torch.tensor(input)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(nn.Module): # we define our neural network as a child class of nn.Module, meaning we inherit all the methods of the parent class nn.Module. Note also that we are not building the network here, but a blueprint to instantiate the network.\n",
    "    def __init__(self, vocab_size, embedding_size):\n",
    "        super().__init__() # instantiates all of the init methods of the parent class\n",
    "        self.embed = nn.Embedding(vocab_size, embedding_size) # an embedding layer to convert the input (the index of the center/context token) into the the one-hot encoding, and then retrieve the weights corresponding to these indices in the lower-dimensional hidden layer\n",
    "        self.expand = nn.Linear(embedding_size, vocab_size, bias = False) # a linear layer to predict the probability of a center/context word given the hidden layer. We disable bias (the intercept) because we rescale our predictions anyways.\n",
    "        \n",
    "\n",
    "    def forward(self, input): # forward(): defining the forward pass\n",
    "        # Encode input to lower-dimensional representation\n",
    "        hidden = self.embed(input)\n",
    "        # Expand hidden layer to prediction\n",
    "        logits = self.expand(hidden) # re-expanding the hidden layer to make predictions. These raw predictions need to be re-scaled using softmax, but we skip this step here as PyTorch implements the relevant steps under Cross Entropy loss\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Training the model\n",
    "\n",
    "Unlike the usual ML or statistical models, when training neural network there's not a clear point at which the model has \"finished\" training. \n",
    "\n",
    "Training in the context of neural networks means repeatedly making predictions using the observations in the dataset and then adjusting the parameters accordingly to correct for the error in predictions. Because we don't want the network to perfectly learn the most recent prediction while forgetting all other predictions, we usually give it a \"learning rate\", which is some penalty on the loss adjustment to prevent fitting only to the most recent observation. \n",
    "\n",
    "The longer we train the network, the more perfectly it will learn the training data, but this often comes with the risk of overfitting and failing to generalise to unseen data. However, given that with Word2Vec is not to infer unseen data, but to descrie \"seen\" data.\n",
    "\n",
    "Though I'm not exactly sure what the implications of overfitting in this context are, it might have something to do with the global and domain-specific (or corpus-specific) meanings of the said word.\n",
    "\n",
    "A simple for-loop is used for the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "EMBED_SIZE = 100 # Quite small, just for the tutorial\n",
    "model = Word2Vec(n_v, EMBED_SIZE)\n",
    "\n",
    "# Time to use those GPUs lol :) [But in case you don't DO NOT USE THIS IF YOU DON'T WANT TO BREAK YOUR PC]\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device) # huehuehuehuehue\n",
    "\n",
    "# Define training parameters\n",
    "LR = 3e-4  # learning rate\n",
    "EPOCHS = 10 # number of times to pass the full training data through the model\n",
    "loss_fn = nn.CrossEntropyLoss() # in short, the appropriate loss function for making categorical predictions\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR) # the algorithm on how to update the parameters as a function of loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running 10 epochs of the loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 529/530 [00:21<00:00, 37.46it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # For progress bars\n",
    "\n",
    "progress_bar = tqdm(range(EPOCHS * len(dataloader['train'])))\n",
    "running_loss = []\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    for center, context in dataloader['train']:\n",
    "        center, context = center.to(device), context.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input=context)\n",
    "        loss = loss_fn(logits, center)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        progress_bar.update(1)\n",
    "    epoch_loss /= len(dataloader['train'])\n",
    "    running_loss.append(epoch_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the running loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcf300dd970>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(running_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we continue the training process, the marginal increase in accuracy overall starts to slow down. But, in this case (with embedding models), accuracy is not the main goal of the model. \n",
    "\n",
    "The embeddings are the edge weights between the hidden layer and the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvecs = model.expand.weight.cpu().detach().numpy()\n",
    "tokens = ['good', 'father', 'school', 'hate']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we get the closests vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good ['go', 'like', 'best', 'amp', '@user', 'make', 'one', 'come', 'feel', 'get'] \n",
      "\n",
      "father ['day', 'anoth', 'dad', '#fathersday', 'happi', 'everyon', '#love', 'one', 'today', 'amp'] \n",
      "\n",
      "school ['enjoy', 'amp', 'night', 'one', 'two', 'day', 'get', 'new', 'next', 'sta'] \n",
      "\n",
      "hate ['go', 'call', '@user', 'could', 'new', 'happi', 'enjoy', 'cant', 'talk', 'like'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "\n",
    "def get_distance_matrix(wordvecs, metric):\n",
    "    dist_matrix = distance.squareform(distance.pdist(wordvecs, metric))\n",
    "    return dist_matrix\n",
    "\n",
    "def get_k_similar_words(word, dist_matrix, k=10):\n",
    "    idx = tok2id[word]\n",
    "    dists = dist_matrix[idx]\n",
    "    ind = np.argpartition(dists, k)[:k+1]\n",
    "    ind = ind[np.argsort(dists[ind])][1:]\n",
    "    out = [(i, id2tok[i]) for i in ind]\n",
    "    return out\n",
    "\n",
    "dmat = get_distance_matrix(wordvecs, 'cosine')\n",
    "for word in tokens:\n",
    "    print(word, [t[1] for t in get_k_similar_words(word, dmat)], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We further train the model for 90 more epochs and see how these change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 530/530 [00:22<00:00, 23.38it/s]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 90\n",
    "progress_bar = tqdm(range(EPOCHS * len(dataloader['train'])))\n",
    "running_loss = []\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    for center, context in dataloader['train']:\n",
    "        center, context = center.to(device), context.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input=context)\n",
    "        loss = loss_fn(logits, center)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        progress_bar.update(1)\n",
    "    epoch_loss /= len(dataloader['train'])\n",
    "    running_loss.append(epoch_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting new word vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good ['@user', 'im', 'today', 'great', 'amp', 'go', 'make', 'one', 'day', 'happi'] \n",
      "\n",
      "father ['dad', 'day', '#fathersday', 'wish', 'love', 'happi', 'one', 'god', 'enjoy', 'bihday'] \n",
      "\n",
      "school ['year', 'tomorrow', 'first', 'new', 'week', 'month', 'two', 'today', 'back', 'last'] \n",
      "\n",
      "hate ['kill', 'peopl', 'call', 'dont', 'say', 'still', 'mani', 'would', 'even', 'much'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordvecs_100_epochs = model.expand.weight.cpu().detach().numpy()\n",
    "dmat_100_epochs = get_distance_matrix(wordvecs_100_epochs, 'cosine')\n",
    "for word in tokens:\n",
    "    print(word, [t[1] for t in get_k_similar_words(word, dmat_100_epochs)], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'word2vec-twitter_hate-100epochs.checkpoint')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
